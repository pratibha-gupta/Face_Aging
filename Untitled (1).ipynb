{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnWvOGlRlx7i",
        "outputId": "f7e60e5d-bf8e-4513-83b5-e68c2ccfb1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from IPython import display\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "import pickle\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkdYQK4emDft"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUFCkY3ADOdq"
      },
      "source": [
        "ENCODER : First we will encode our image data because when we are dealing with millions of image its important to compress them There are a lot of compression techniques. The Encoder is tasked with finding the smallest possible representation of data that it can store - extracting the most prominent features of the original data and representing it in a way the decoder can understand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYczWfDaDMWi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-_haUE2cM5j",
        "outputId": "1932816f-487a-4996-ba49-6285c7546942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXRZ8I6KcNBM",
        "outputId": "2685e562-fe2d-4fd6-eeb0-e90921f9f493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd \"/content/drive/My Drive/data/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De84TVfZcNMS",
        "outputId": "906e275b-34b4-48d8-9310-b893a264862f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#  !unzip \"/content/drive/My Drive/UTKFace.tar.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/UTKFace.tar.gz\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/drive/My Drive/UTKFace.tar.gz or\n",
            "        /content/drive/My Drive/UTKFace.tar.gz.zip, and cannot find /content/drive/My Drive/UTKFace.tar.gz.ZIP, period.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfHoRxbGaw2x"
      },
      "source": [
        "def build_encoder():\n",
        "  input_layer = Input(shape = (64,64,3))\n",
        "  enc = Conv2D(filters=32, kernel_size=5, strides=2, padding='same')(input_layer)\n",
        "  enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "  enc = Conv2D(filters=64, kernel_size=5, strides=2, padding='same')(input_layer)\n",
        "  enc = BatchNormalization()(enc)\n",
        "  enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "  enc = Flatten()(enc)\n",
        "\n",
        "    # 1st Fully Connected Layer\n",
        "  enc = Dense(4096)(enc)\n",
        "  enc = BatchNormalization()(enc)\n",
        "  enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "    # Second Fully Connected Layer\n",
        "  enc = Dense(100)(enc)\n",
        "\n",
        "    # Create a model\n",
        "  model = Model(inputs=[input_layer], outputs=[enc])\n",
        "  return model\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QymNlHf8hmj"
      },
      "source": [
        "Lets make generator.\n",
        "Generator helps to generate images based on real images. For this we add some random noise in original image and with every run it generate neww image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZis3O6aa5l4"
      },
      "source": [
        "def generator():\n",
        "\n",
        "  input_z_noise = Input(shape=(latent_dims,))\n",
        "  input_label = Input(shape=(num_classes,))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0uPvqL27IIg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}