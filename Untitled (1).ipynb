{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnWvOGlRlx7i",
        "outputId": "f7e60e5d-bf8e-4513-83b5-e68c2ccfb1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from IPython import display\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "import pickle\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkdYQK4emDft"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUFCkY3ADOdq"
      },
      "source": [
        "ENCODER : First we will encode our image data because when we are dealing with millions of image its important to compress them There are a lot of compression techniques. The Encoder is tasked with finding the smallest possible representation of data that it can store - extracting the most prominent features of the original data and representing it in a way the decoder can understand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYczWfDaDMWi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-_haUE2cM5j",
        "outputId": "1932816f-487a-4996-ba49-6285c7546942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXRZ8I6KcNBM",
        "outputId": "2685e562-fe2d-4fd6-eeb0-e90921f9f493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd \"/content/drive/My Drive/data/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De84TVfZcNMS",
        "outputId": "906e275b-34b4-48d8-9310-b893a264862f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#  !unzip \"/content/drive/My Drive/UTKFace.tar.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/UTKFace.tar.gz\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/drive/My Drive/UTKFace.tar.gz or\n",
            "        /content/drive/My Drive/UTKFace.tar.gz.zip, and cannot find /content/drive/My Drive/UTKFace.tar.gz.ZIP, period.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfHoRxbGaw2x"
      },
      "source": [
        "def build_encoder():\n",
        "  input_layer = Input(shape = (64,64,3))\n",
        "  enc = Conv2D(filters=32, kernel_size=5, strides=2, padding='same')(input_layer)\n",
        "  enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "  enc = Conv2D(filters=64, kernel_size=5, strides=2, padding='same')(input_layer)\n",
        "  enc = BatchNormalization()(enc)\n",
        "  enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "  enc = Flatten()(enc)\n",
        "\n",
        "    # 1st Fully Connected Layer\n",
        "  enc = Dense(4096)(enc)\n",
        "  enc = BatchNormalization()(enc)\n",
        "  enc = LeakyReLU(alpha=0.2)(enc)\n",
        "\n",
        "    # Second Fully Connected Layer\n",
        "  enc = Dense(100)(enc)\n",
        "\n",
        "    # Create a model\n",
        "  model = Model(inputs=[input_layer], outputs=[enc])\n",
        "  return model\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QymNlHf8hmj"
      },
      "source": [
        "Lets make generator.\n",
        "\n",
        "\n",
        "Generator helps to generate images based on real images. For this we add some random noise in original image and with every run it generate new image.\n",
        "\n",
        "Two common types of layers that can be used in the generator model are a upsample layer (UpSampling2D) and transpose convolutional layer (Conv2DTranspose).\n",
        "\n",
        "\n",
        "*   Generative models in the GAN architecture are required to upsample input data in order to generate an output image.\n",
        "*   The Upsampling layer is a simple layer with no weights that will double the dimensions of input and can be used in a generative model when followed by a traditional convolutional layer.\n",
        "\n",
        "\n",
        "*  The Transpose Convolutional layer is an inverse convolutional layer that will both upsample input and learn how to fill in details during the model training process.\n",
        "\n",
        "Batch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch. This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs required to train deep networks.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZis3O6aa5l4"
      },
      "source": [
        "def generator():\n",
        "\n",
        "  input_z_noise = Input(shape=(latent_dims,))\n",
        "  input_label = Input(shape=(num_classes,))\n",
        "  x = concatenate([input_z_noise, input_label])\n",
        "  \n",
        "  x = Dense(2048, input_dim = latent_dims + num_classes)(x)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  \n",
        "  x = Dense(256 * 8 * 8)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  \n",
        "  x = Reshape((8, 8, 256))(x)\n",
        "  \n",
        "  x = UpSampling2D(size = (2, 2))(x)\n",
        "  x = Conv2D(filters = 128, kernel_size = 5, padding = 'same')(x)\n",
        "  x = BatchNormalization(momentum = 0.8)(x)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  \n",
        "  x = UpSampling2D(size = (2, 2))(x)\n",
        "  x = Conv2D(filters = 64, kernel_size = 5, padding = 'same')(x)\n",
        "  x = BatchNormalization(momentum = 0.8)(x)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  \n",
        "  x = UpSampling2D(size = (2, 2))(x)\n",
        "  x = Conv2D(filters = 3, kernel_size = 5, padding = 'same')(x)\n",
        "  x = BatchNormalization(momentum = 0.8)(x)\n",
        "  x = Activation('tanh')(x)\n",
        "  \n",
        "  model = Model(inputs = [input_z_noise, input_label], outputs = [x])\n",
        "  \n",
        "  model.summary()\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0uPvqL27IIg"
      },
      "source": [
        "def expand_label_input(x):\n",
        "  x = K.expand_dims(x, axis = 1)\n",
        "  x = K.expand_dims(x, axis=1)\n",
        "  x = K.tile(x, [1, 32, 32, 1])\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWvOxcx76eM8"
      },
      "source": [
        "Discriminator: \n",
        "The discriminator in a GAN is simply a classifier. It tries to distinguish real data from the data created by the generator. It could use any network architecture appropriate to the type of data it's classifying.\n",
        "The discriminator's training data comes from two sources:\n",
        "\n",
        "Real data instances, such as real pictures of people. The discriminator uses these instances as positive examples during training.\n",
        "Fake data instances created by the generator. The discriminator uses these instances as negative examples during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Vsxl10jtJKq"
      },
      "source": [
        "def build_disc():\n",
        "  \n",
        "  input_shape = (64, 64, 3)\n",
        "  label_shape = (6,)\n",
        "  \n",
        "  image_input = Input(shape = input_shape)\n",
        "  label_input = Input(shape = label_shape)\n",
        "  \n",
        "  x = Conv2D(filters = 64, kernel_size = 3, strides = 2, padding = 'same')(image_input)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  \n",
        "  label_input1 = Lambda(expand_label_input)(label_input)\n",
        "  \n",
        "  x = concatenate([x, label_input1], axis = 3)\n",
        "  \n",
        "  x = Conv2D(128, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  \n",
        "  x = Conv2D(256, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  \n",
        "  x = Conv2D(512, kernel_size = 3, strides = 2, padding = 'same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha = 0.2)(x)\n",
        "  \n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1, activation = 'sigmoid')(x)\n",
        "  \n",
        "  model = Model(inputs = [image_input, label_input], outputs = [x])\n",
        "  \n",
        "  model.summary()\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tg_Aw7nQHbG"
      },
      "source": [
        "Training GAN network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvGE3fgQ6cE9"
      },
      "source": [
        "def train_gan():\n",
        "  \n",
        "  data_dir = \"/content/data/\"\n",
        "  wiki_dir = os.path.join(data_dir, \"wiki_crop\")\n",
        "  epochs = 500\n",
        "  batch_size = 128\n",
        "  image_shape = (64, 64, 3)\n",
        "  z_shape = 100\n",
        "  TRAIN_GAN = True\n",
        "  TRAIN_ENCODER = False\n",
        "  TRAIN_GAN_WITH_FR = False\n",
        "  fr_image_shape = (192, 192, 3)\n",
        "  \n",
        "  disc_optimizer = Adam(lr = 0.0002, beta_1 = 0.5, beta_2 = 0.999, epsilon = 10e-8)\n",
        "  gen_optimizer = Adam(lr = 0.0002, beta_1 = 0.5, beta_2 = 0.999, epsilon = 10e-8)\n",
        "  adversarial_optimizer = Adam(lr = 0.0002, beta_1 = 0.5, beta_2 = 0.999, epsilon = 10e-8)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}